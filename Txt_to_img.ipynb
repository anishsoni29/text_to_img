{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9e8a763",
   "metadata": {},
   "source": [
    "## Text to image generation using Stable Diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c48c27",
   "metadata": {},
   "source": [
    "### Installing the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e234895",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install diffusers==0.3.0 --q\n",
    "!pip install transformers scipy ftfy --q\n",
    "!pip install kaggle --q\n",
    "!pip install \"ipywidgets>=7,<8\" --q\n",
    "import IPython.display "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdae6275",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2cbf2cfd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_token' from 'transformers' (/Users/anishsoni/anaconda3/lib/python3.10/site-packages/transformers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 15\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdiffusers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LMSDiscreteScheduler , PNDMScheduler\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_token\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Set your Hugging Face API token\u001b[39;00m\n\u001b[1;32m     18\u001b[0m api_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhf_IQudNZvpotVjTrvEEBXWueJTmXcQkSJhJj\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'get_token' from 'transformers' (/Users/anishsoni/anaconda3/lib/python3.10/site-packages/transformers/__init__.py)"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "from PIL import Image\n",
    "import IPython.display \n",
    "from torch import autocast\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import CLIPTextModel, CLIPTokenizer\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from diffusers import AutoencoderKL, UNet2DConditionModel\n",
    "from diffusers import LMSDiscreteScheduler , PNDMScheduler\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "from transformers import get_token\n",
    "\n",
    "# Set your Hugging Face API token\n",
    "api_token = \"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\"\n",
    "\n",
    "# Set the API token for Hugging Face\n",
    "os.environ[\"HF_HOME\"] = os.path.join(os.getcwd(), \".huggingface\")\n",
    "get_token(api_token=api_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54c5da4",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f40d801",
   "metadata": {},
   "outputs": [],
   "source": [
    "class config : \n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    HEIGHT = 512                        \n",
    "    WIDTH = 512                         \n",
    "    NUM_INFERENCE_STEPS = 500            \n",
    "    GUIDANCE_SCALE = 7.5                \n",
    "    GENERATOR = torch.manual_seed(48)   \n",
    "    BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3ef82c",
   "metadata": {},
   "source": [
    "### Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9297a01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_grid(imgs, rows, cols):\n",
    "    assert len(imgs) == rows*cols\n",
    "    w,h = img[0].size\n",
    "    grid = Image.new('RGB', size = (cols*w, rows*h))\n",
    "    grid_w, grid_h = grid.size\n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14efa7e",
   "metadata": {},
   "source": [
    "### Pipeline -- loading the pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70bf73ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Hugging_face' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[0;32m----> 4\u001b[0m vae \u001b[38;5;241m=\u001b[39m AutoencoderKL\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompVis/stable-diffusion-v1-4\u001b[39m\u001b[38;5;124m\"\u001b[39m, subfolder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvae\u001b[39m\u001b[38;5;124m\"\u001b[39m, use_auth_token\u001b[38;5;241m=\u001b[39m\u001b[43mHugging_face\u001b[49m)\n\u001b[1;32m      5\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m CLIPTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai/clip-vit-large-patch14\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m text_encoder \u001b[38;5;241m=\u001b[39m CLIPTextModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai/clip-vit-large-patch14\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Hugging_face' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "vae = AutoencoderKL.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"vae\", use_auth_token=Hugging_face)\n",
    "tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "unet = UNet2DConditionModel.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"unet\", use_auth_token=Hugging_face)\n",
    "vae = vae.to(config.DEVICE)\n",
    "text_encoder = text_encoder.to(config.DEVICE)\n",
    "unet = unet.to(config.DEVICE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "facec76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mTokenizer, Text Encoder, VAE, Unet are loaded !!\n"
     ]
    }
   ],
   "source": [
    "print(f'\\033[94mTokenizer, Text Encoder, VAE, Unet are loaded !!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b0a98f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mThe scheduler loaded is K-LMS Sceheduler\n"
     ]
    }
   ],
   "source": [
    "scheduler = LMSDiscreteScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", num_train_timesteps=1000)\n",
    "print(f'\\033[94mThe scheduler loaded is K-LMS Sceheduler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed48852d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
